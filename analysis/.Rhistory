#            investigating the world.
#          - Also, it's the least informative state, so it
#            can be useful when considering the most likely
#            outcomes for a model.
#### 4.2: Language for describing models ####
# just a brief discussion of a couple of points, kind of
# useful, but not insanely
#### 4.3: Guassian model of height ####
# for this section, we use the data below
data(Howell1)
d <- Howell1
# The data has four columns; height (cm), weight (kg),
# age (years), and gender (0 = female, 1 = male)
# for now, we only care about adults as age strongly correlates
# with height so we want to remove that
d2 <- d[d$age >= 18,]
# plot dist of heights
dens(d2$height)
# so now we can think about some weakly informative priors
# our model will be something like this
# h ~ Normal(mu, sigma)
# mu ~ Normal(178,20)
# sigma ~ Uniform(0,50)
# and we can see what this looks like by simulating it
sample_mu <- rnorm(1e4, 178, 20)
sample_sigma <- runif(1e4, 0, 50)
prior_h <- rnorm(1e4, sample_mu, sample_sigma)
dens(prior_h)
# so now onto the "actual" model
mu_list <- seq(from = 140, to = 160, length.out = 200)
sigma_list <- seq(from = 4, to = 9, length.out = 200)
post <- expand.grid(mu=mu_list, sigma=sigma_list)
post$LL <- sapply(1:nrow(post), function(i) sum( dnorm(
d2$height,
mean=post$mu[i],
sd=post$sigma[i],
log = TRUE)))
post$prod <- post$LL + dnorm(post$mu, 178, 20, TRUE) +
dunif(post$sigma, 0, 50, TRUE)
post$prob <- exp(post$prod - max(post$prod))
# inspect the posterior distribution
contour_xyz(post$mu, post$sigma, post$prob)
# or a simple heat map
image_xyz(post$mu, post$sigma, post$prob)
# now we want to take samples, but in this case we have
# two parameters to look at, so we need something like this
sample_rows <- sample(1:nrow(post), size = 1e4, replace = T,
prob = post$prob)
sample.mu <- post$mu[sample_rows]
sample.sigma <- post$sigma[sample_rows]
# what does this look like?
plot(sample.mu, sample.sigma, cex = 0.5, pch = 16, col=col.alpha(rangi2,0.1))
#### fitting the model with map ####
# he reloads the data here... not sure why but to be safe
data(Howell1)
d <- Howell1
d2 <- d[d$age >= 18,]
# now the map version
flist <- alist(
height ~ dnorm(mu, sigma),
mu ~ dnorm(178, 20),
sigma ~ dunif(0,50)
)
# notice there is not data = part here, that comes later
m4.1 <- map(flist, data = d2)
# check the resulst
precis(m4.1)
# to be a bit more clever, we can add in start values
# This means the model will converge quicker, it it
# has a reasonable starting point.
start <- list(
mu = mean(d2$height),
sigma = sd(d2$height)
)
# list requires things to actually be produced
# alist lets you do anything, so this is good for models
# by do anything, I mean it doesn't execute the list
# as code, so it just lets it sit there
# what about more specific priors
m4.2 <- map(
alist(
height ~ dnorm(mu, sigma),
mu ~ dnorm(178, 0.1),
sigma ~ dunif(0, 50)
),
data = d2)
precis(m4.2)
# we can see how each parameter relates to another by;
vcov(m4.1)
# this is more helpful
cov2cor(vcov(m4.1))
# this shows how they relate to one another in a way
# such that how useful is knowing one of the variables?
# a value close to 0 says that learning about one, tells
# us very little about the other. 1 being that we
# learn a lot... or they're very closey related in
# in other words.
# What about extracting samples... there's a function
post <- extract.samples(m4.1, n = 1e4)
head(post)
# using precis on this will give the HPDI of 89%
precis(post)
#### 4.4 Adding a predictor ####
# By removing age, we lose out on a predictor, and usually
# we want to predict things based on other things with the
# models that are built.
# Make a plot of height by weight observed in this data set
plot(d2$height ~ d2$weight)
# Probably obvious... but they correlate with one another
# quite well (at a glance...). But this is not a precise
# way of doing it. We get a vague sense, but nothing more
# so how about seeing how well this model performs when
# using weight as a predictor in a regression analysis
m4.3 <- map(
alist(
height ~ dnorm(mu,sigma),
mu <- a + b*weight,
a ~ dnorm(156,100),
b ~ dnorm(0,10),
sigma ~ dunif(0,50)
) ,
data = d2)
# can just use precis() to check the model... but sometimes
# this isn't enough. we can do precis(model, corr=T) to get
# more information
precis(m4.3, corr=T)
# this shows a strong relationship between b and a... so as
# you change the slope, the intercept changes to account for
# this. Not that big a problem with a simple model, but can be
# for more complex ones. It suggests that the two predictors
# carry the same information.
# to avoid this problem... we often use centering.
d2$weight.c <- d2$weight - mean(d2$weight)
# now mean(d2$weight.c) is 0 (pretty much...)
# we can run the model with this now
m4.4 <- map(
alist(
height ~ dnorm(mu,sigma),
mu <- a + b*weight.c,
a ~ dnorm(156,100),
b ~ dnorm(0,10),
sigma ~ dunif(0,50)
) ,
data = d2)
# the estimates for b and sigma are unchanged, but now a is
# more reflective of the mean of the data because 0 weight
# actually means something now rather than the absence of
# weight.
# let's make some plots to make sure things are ok... as if
# we couldn't tell from the precis output
# Put the map values over the actual data
plot(height ~ weight, data = d2)
abline(a=coef(m4.3)["a"], b = coef(m4.3)["b"])
# using coef extracts a value from the model that was fitted
# in this case, it gets the intercept and slope values
# However, the above does a poor job of explaning the
# the is inherent in any model like this
# one way to do this is get a bunch of lines that are from
# samples in the model
post <- extract.samples(m4.3)
# the exact values aren't that important, but it gives us
# an idea of the "spread" and therefore the uncertainty. the
# average of all these should give us the MAP values
# For this part, we will use progressively more data each time
# so we can see how that effects the scatter of the lines
N <- 10 # change this number to see how predictions change
dN <- d2[1:N, ]
mN <- map(
alist(
height ~ dnorm(mu, sigma),
mu <- a + b*weight,
a ~ dnorm(178, 100),
b ~ dnorm(0, 10),
sigma ~ dunif(0,50)
),
data = dN)
# now let's extract samples and plot 20 of these lines
post <- extract.samples(mN, n = 20)
# display data
plot(dN$weight, dN$height,
xlim = range(dN$weight), ylim = range(dN$height),
col = rangi2)
# plot lines with transparency
for( i in 1:20 )
abline(a = post$a[i], b = post$b[i], col = col.alpha("black" , 0.3))
# plotting regression intervals and contours
# this part will just show you how to do that. Think about one
# value for weight (say 50kg), we can get a bunch of values for
# mu for someone of this weight
# redefine post as this first
post <- extract.samples(m4.3)
# now get some example values
mu_at_50 <- post$a + post$b * 50
# so what does the shape of this look like?
dens(mu_at_50, col = rangi2, lwd = 2)
# let's look for an interval in this
HPDI(mu_at_50, prob = 0.89)
# this is great... but long winded if we had to do this
# for every weight value in the model...
# so we can use the "link()" function to save some time
mu <- link(m4.3)
str(mu)
# all this does is take the model, and compute the mu value
# for each case in the data
# So this has give us a distribution of mu for each individual
# but we want one for each unique weight, so we do something
# a bit different
# define seq of weights
weight.seq <- seq(from = 25, to = 70, by = 1)
# use link()
mu <- link(m4.3, data = data.frame(weight = weight.seq))
str(mu)
# time to visualise this
plot(height ~ weight, d2, type="n")
# loop over samples and plot mu values
for(i in 1:100)
points(weight.seq, mu[i], pch = 16, col = col.alpha(rangi2,0.1))
for(i in 1:100)
points(weight.seq, mu[i,], pch = 16, col = col.alpha(rangi2,0.1))
mu.mean <- apply(mu, 2, mean)
mu.HPDO <- apply(mu, 2, HDPI, prob=0.89)
mu.mean <- apply(mu, 2, mean)
mu.HPDI <- apply(mu, 2, HPDI, prob=0.89)
mu,mea
mu.mean
mu.HPDI
plot(height ~ weight, data = d2, col = col.alpha(rangi2, 0.5))
# plot MAP line
lines(weight.seq, mu.mean)
# add in shaded region
shade(mu.HPDI, weight.seq)
sim.height <- sim(m4.3, data = list(weight = weight.seq))
str(sim.height)
height.PI <- apply(sim.heigh, 2, PI, prob = 0.89)
height.PI <- apply(sim.height, 2, PI, prob = 0.89)
plot(height~weight, d2, col = col.alpha(rangi2, 0.5))
# draw MAP
lines(weight.seq, mu.mean)
# drar HPDI region
shade(mu.HPDI, weight.seq)
# drar PI region for simulated heights
shade(height.PI, weight.seq)
rm(list = ls())
data(Howell1)
d <- Howell1
str(d)
plot(height~weight)
plot(height~weight, d)
d$weight.s <- (d$weight - mean(d$weight))/sd(d$weight)
mean(d$weight.s)
d$weight.s2 <- d$weight.s^2
m4.5 <- map(
alist(
height ~ dnorm(mu, sigma),
mu <- a + b1*weight.s + b2*weight.s2 ,
a ~ dnorm(178, 100),
b1 ~ dnorm(0, 10),
b2 ~ dnorm(0, 10),
sigma ~ dunif(0, 50)
),
data = d)
precis(m4.5)
weight.seq <- seq(from = -2.2, to = 2, length.out = 30)
pred_dat <- list(weight.s=weight.seq, weight.s2=weight.seq^2)
mu <- link(m4.5, data = pred_dat)
mu.mean <- apply(mu, 2, mean)
mu.PI <- apply(mu, 2, PI, prob = 0.89)
sim.height <- sim(m4.5, data = pred_dat)
height.PI <- apply(sim.height, 2, PI, prob = 0.89)
plot(height ~ weight.s, d, col = col.alpha(rani2,0.5))
lines(weight.seq, mu.mean)
shade(mu.PI, weight.seq)
shade(height.PI, weight.seq)
plot(height ~ weight.s, d, col = col.alpha(rangi2,0.5))
lines(weight.seq, mu.mean)
shade(mu.PI, weight.seq)
shade(height.PI, weight.seq)
d$weight.s3 <- d$weight.s^3
# add in the extra term again
m4.6 <- mapply(
alist(
height ~ dnorm(mu,sigma),
mu <- a + b1*weight.s + b2*weight.s2 + b3*weight.s3,
a ~ dnorm(178,100),
b1 ~ dnorm(0,10),
b2 ~ dnorm(0,10),
b3 ~ dnorm(0,10),
sigma ~ dunif(0,50)
),
data = d)
m4.6 <- map(
alist(
height ~ dnorm(mu,sigma),
mu <- a + b1*weight.s + b2*weight.s2 + b3*weight.s3,
a ~ dnorm(178,100),
b1 ~ dnorm(0,10),
b2 ~ dnorm(0,10),
b3 ~ dnorm(0,10),
sigma ~ dunif(0,50)
),
data = d)
test <- replicate(1e4, prod(0, 0, 10))
test
test <- replicate(1e4, prod(12, 0, 10))
head(test)
sim_mu <- rnorm(1e4, 0, 10)
sim_sig <- runif(1e4, 0, 10)
sim_prior <- rnorm(1e4, sim_mu, sim_sig)
sim_mu <- rnorm(1e4, 0, 10)
sim_sig <- runif(1e4, 0, 10)
sim_prior <- rnorm(1e4, sim_mu, sim_sig)
dens(sim_prior)
data(Howell1)
d <- Howell1
d2 <- d[d$age >= 18,]
rm(d)
d2$weight.s <- (d2$weight - mean(d2$weight)) / sd(d2$weight)
m4.4 <- map(
alist(
height ~ dnorm(mu,sigma),
mu <- a + b*weight.c,
a ~ dnorm(156,100),
b ~ dnorm(0,10),
sigma ~ dunif(0,50)
) ,
data = d2)
m4.4 <- map(
alist(
height ~ dnorm(mu,sigma),
mu <- a + b*weight.s,
a ~ dnorm(156,100),
b ~ dnorm(0,10),
sigma ~ dunif(0,50)
) ,
data = d2)
m4.H1 <- map(
alist(
height ~ dnorm(mu,sigma),
mu <- a + b*weight.s,
a ~ dnorm(156,100),
b ~ dnorm(0,10),
sigma ~ dunif(0,50)
) ,
data = d2)
post <- extract.samples(m4.H1)
mu_at_50 <- post$a + post$b * 50
mu_at_50
d2$weight.c <- d2$weight - mean(d2$weight)
m4.H1 <- map(
alist(
height ~ dnorm(mu,sigma),
mu <- a + b*weight.c,
a ~ dnorm(156,100),
b ~ dnorm(0,10),
sigma ~ dunif(0,50)
) ,
data = d2)
# now let's extract some stuff
post <- extract.samples(m4.H1)
m4.H1 <- map(
alist(
height ~ dnorm(mu,sigma),
mu <- a + b*weight.c,
a ~ dnorm(156,100),
b ~ dnorm(0,10),
sigma ~ dunif(0,50)
) ,
data = d2)
post <- extract.samples(m4.H1)
mu_at_50 <- post$a + post$b * 50
mean(mu_at_50)
m4.H1 <- map(
alist(
height ~ dnorm(mu,sigma),
mu <- a + b*weight,
a ~ dnorm(156,100),
b ~ dnorm(0,10),
sigma ~ dunif(0,50)
) ,
data = d2)
# now let's extract some stuff
post <- extract.samples(m4.H1)
mu_at_50 <- post$a + post$b * 50
mean(mu_at_50)
m4.H1 <- map(
alist(
height ~ dnorm(mu,sigma),
mu <- a + b*weight,
a ~ dnorm(178,100),
b ~ dnorm(0,10),
sigma ~ dunif(0,50)
) ,
data = d2)
# now let's extract some stuff
post <- extract.samples(m4.H1)
mu_at_50 <- post$a + post$b * 50
mean(mu_at_50)
weights_to_check <- c(46.95, 43.72, 64.78, 32.59, 54.63)
d = NULL
d = rbind(d, data.frame(weights_to_check))
d
for(i in weights_to_check)
temp <- post$a + post$b * i
Expected_height <- mean(temp)
Int89 <- HPDI(temp, prob = 0.89)
d = rbind(d, data.frame(weights_to_check, Expected_height, Int89))
rm(d)
d = NULL
for(i in weights_to_check)
temp <- post$a + post$b * i
Expected_height <- mean(temp)
Int89 <- HPDI(temp, prob = 0.89)
d = rbind(d, data.frame(weights_to_check, Expected_height, Int89))
temp <- post$a + post$b * 50
Int89 <- HPDI(temp, prob = 0.89)
Int89
Int89[1]
for(i in weights_to_check) {
temp <- post$a + post$b * i
Expected_height <- mean(temp)
Int89 <- HPDI(temp, prob = 0.89)
d = rbind(d, data.frame(weights_to_check, Expected_height, Int89[1], Int89[2]))
}
rm(d)
d = NULL
for(i in weights_to_check) {
temp <- post$a + post$b * i
Expected_height <- mean(temp)
Int89 <- HPDI(temp, prob = 0.89)
lower <- Int89[1]
upper <- Int89[2]
d = rbind(d, data.frame(weights_to_check, Expected_height, lower, upper))
}
for(i in weights_to_check) {
temp <- post$a + post$b * i
Expected_height <- mean(temp)
Int89 <- HPDI(temp, prob = 0.89)
lower <- Int89[1]
upper <- Int89[2]
d = rbind(d, data.frame(weights_to_check[i], Expected_height, lower, upper))
}
for(i in weights_to_check) {
temp <- post$a + post$b * i
Expected_height <- mean(temp)
Int89 <- HPDI(temp, prob = 0.89)
lower <- Int89[1]
upper <- Int89[2]
d = rbind(d, data.frame(i, Expected_height, lower, upper))
}
d = NULL
for(i in weights_to_check) {
temp <- post$a + post$b * i
Expected_height <- mean(temp)
Int89 <- HPDI(temp, prob = 0.89)
lower <- Int89[1]
upper <- Int89[2]
d = rbind(d, data.frame(i, Expected_height, lower, upper))
}
head(d)
d = NULL
for(i in weights_to_check) {
temp <- post$a + post$b * i
Expected_height <- mean(temp)
Int89 <- HPDI(temp, prob = 0.89)
lower <- Int89[1]
upper <- Int89[2]
Weights <- i
d = rbind(d, data.frame(Weights, Expected_height, lower, upper))
}
head(d)
d = NULL
for(i in weights_to_check) {
temp <- post$a + post$b * i
Expected_height <- mean(temp)
Int89 <- HPDI(temp, prob = 0.89)
lower <- Int89[1,]
upper <- Int89[2,]
Weights <- i
d = rbind(d, data.frame(Weights, Expected_height, lower, upper))
}
d = NULL
for(i in weights_to_check) {
temp <- post$a + post$b * i
Expected_height <- mean(temp)
Int89 <- HPDI(temp, prob = 0.89)
lower <- Int89[,1]
upper <- Int89[,2]
Weights <- i
d = rbind(d, data.frame(Weights, Expected_height, lower, upper))
}
d = NULL
for(i in weights_to_check) {
temp <- post$a + post$b * i
Expected_height <- mean(temp)
Int89 <- HPDI(temp, prob = 0.89)
lower <- Int89[1]
upper <- Int89[2]
Weights <- i
d = rbind(d, data.frame(Weights, Expected_height, lower, upper))
}
temp <- post$a + post$b * 50
HDPI(temp)
HPDI(temp)
HPDI(temp)[1]
HPDI(temp)[2]
head(d)
d
setwd("F:/Uni/Github/TargetAbsentStoppingRules/analysis")
load("scratch/models/m_ta_only_temp_2")
precis(m_ta_only_temp_2)
precis(m_ta_only_temp_2, depth=2)
stancode(m_ta_only_temp_2)
